{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small><i>This notebook is based on the 2016 AAS Python Workshop tutorial on tables, available on [GitHub](https://github.com/spacetelescope/AAS2016), though it has been modified. Some was also borrowed from a notebook put together by [Jake Vanderplas](http://www.vanderplas.com) and has been modified to suit the purposes of this course, including expansion/modification of explanations and additional exercises. Source and license info for the original is on [GitHub](https://github.com/jakevdp/2014_fall_ASTR599/)</i></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *** Names: [Insert Your Name Here]***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prelab 5 - Pandas\n",
    "\n",
    "### Prelab 5 Contents\n",
    "1. Pandas Basics\n",
    "     * Intro to Pandas  \n",
    "     * Pandas Dataframes  \n",
    "     * Reading in Tabular Data with Pandas  \n",
    "2. Working with DataFrames\n",
    "    * DataFrame Methods  \n",
    "    * The `describe()` method \n",
    "    * Computing Descriptive Statistics for DataFrame Columns  \n",
    "    * Indexing DataFrames  \n",
    "    * Making DataFrames  \n",
    "    * Converting DataFrames to Numpy  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Basics\n",
    "\n",
    "## 1.1 Intro to Pandas\n",
    "\n",
    "The [Pandas](http://pandas.pydata.org/pandas-docs/stable/) package provides a powerful, high-performance table object via the [DataFrame](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame) class. If there are things that you want to do with tabular data, odds are that Pandas has some built-in functionality for it, and there are many resources available on-line.  A good starting point is the main tutorials site at http://pandas.pydata.org/pandas-docs/stable/tutorials.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Pandas Dataframes\n",
    "Data frames, which are essentially Python tables, are defined like dictionaries with a column header/label (similar to a key for a python dictionary) and a list of entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a': [10,20,30],\n",
    "                   'b': [40,50,60]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "think of DataFrames as numpy arrays plus some extra pointers to their columns and the indices of the row entries that make them amenable to display as tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hit shift + tab tab in the cell below to read more about dataframe objects and operations\n",
    "#Make sure to comment out the cell afterward so that your Prelab compiles.\n",
    "df."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Reading in Tabular Data with Pandas\n",
    "Pandas has built-in functions for reading all kinds of types of data. In the cell below, hit tab once after the r to see all of the read functions. You can download tabular data in almost any format and read it in with Pandas as long as you specify the right read function. Make sure to comment out the cell afterward so that your Prelab compiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read in an excel spreadsheet with some asteroid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asteroids = pd.read_excel(\"asteroids5000.xlsx\")\n",
    "asteroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asteroids.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas dataframe columns can be called as python series using the syntax dataframe.columnlabel, as below, which is why it usually makes sense to define a column name/label that is short and has no spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asteroids.ra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Python decided that you didn't really want to see all 928 entries in the list and employed a ... to obscure the middle. If you really want to see all the entries in a table, column, etc, use a print statement with an asterisk before the object you want it to print. Uncomment the cell below and try it, but you will quickly see why this is not always a good idea, so comment it back out afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(*asteroids.ra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Working with Pandas DataFrames\n",
    "\n",
    "## 2.1 DataFrame Methods\n",
    "\n",
    "There are a number of useful built-in methods for Pandas DataFrames, which can be called with the syntax dataframe.method. A few examples are below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this one counts how many occurrences there are in the table for each unique value in the ph_qual column\n",
    "asteroids.ph_qual.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints the data types for all columns\n",
    "asteroids.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hit tab after the . below to see a full list of available methods. so many!\n",
    "#Again, make sure to comment out the cell afterward so that your Prelab compiles.\n",
    "asteroids."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 The `describe()` method\n",
    "\n",
    "There are also a whole bunch of built in functions that can operate on a pandas dataframe that become available once you've defined it. To see a full list type data. in an empty frame and then hit tab. \n",
    "\n",
    "An especially useful one is dataframe.describe() method, which creates a summary table with some common statistics for all of the columns in the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asteroids.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Computing Descriptive Statistics for DataFrame Columns\n",
    "\n",
    "You can also of course compute descriptive statistics for columns in a pandas dataframe individually. Examples of each one applied to a single column - the object's J-H \"color\" (the difference between it's brightness at two IR wavelengths called J and H-bands) - are given below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(asteroids[\"j_h\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#or\n",
    "asteroids[\"j_h\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asteroids[\"j_h\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asteroids[\"j_h\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asteroids[\"j_h\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to count all of the non-zero values\n",
    "asteroids[\"j_h\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note the answer is different with len because len will count NaNs\n",
    "len(asteroids[\"j_h\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard deviation\n",
    "asteroids[\"j_h\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variance\n",
    "asteroids[\"j_h\"].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quantiles\n",
    "asteroids[\"j_h\"].quantile(0.5) # should return the median!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asteroids[\"j_h\"].quantile(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asteroids[\"j_h\"].quantile(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interquartile Range\n",
    "asteroids[\"j_h\"].quantile(0.75)-asteroids[\"j_h\"].quantile(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skew\n",
    "asteroids[\"j_h\"].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kurtosis\n",
    "asteroids[\"j_h\"].kurtosis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some statistical methods are a bit more useful with categorical (or at least non-continuous) variables, so let's use a different column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the value_counts method will tell you how many times each value appears in the column\n",
    "asteroids[\"ph_qual\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=hw>\n",
    "    \n",
    "### Exercise 1\n",
    "------------------\n",
    "\n",
    "The Quantitative Reasoning for College Science (QuaRCS) assessment is an assessment instrument that Profssor Follette has been administering in general education science classes across the country since 2012. It consists of 25 quantitative questions involving \"real world\" mathematical skills plus 24 attitudinal and demographic questions. It has been administered to more than 5000 students at eleven institutions.\n",
    "\n",
    "A description of all of the variables (pandas dataframe columns) in the QuaRCS dataset and what each numerical answer choice \"stands for\" is in the file variable_descriptions.pdf. \n",
    "\n",
    "(a) Code to read the data from the file AST200_data_anonymized.csv into a pandas dataframe and clean it up a little is in the cell below. Add a comment above each line describing what it's doing.     \n",
    "(b) Choose one categorical and one continuous variable that seems interesting to you and compute all of the statistics from the list above ***in one code cell per variable*** (use print statements) for each variable.   \n",
    "(c) Take a step back from the numbers themselves and consider the results of (b). Are there some statistics that are more appropriate or informative when describing a continuous variable? Make a data-driven argument (e.g. using specific examples from the results of (b)) regarding which statistics should be used when describing categorical and continuous variables and which should not be used.  \n",
    "(d) Write a paragraph describing all of the statistics that are informative for your chosen variables in words. An example is given below for PRE_SCORE. Because score is numerical ***and*** discrete, all of the statistics above are informative. In your two cases, fewer statistics will be informative, so your explanations may be shorter, though you should challenge yourselves to go beyond merely reporting the statistcs, and should interpret them as well, as below.   \n",
    "*QuaRCS score can take discrete integer values between 0 and 25. The minimum score for this dataset is 1 and the maximum is 25. There are 2,777 valid entries for score in this QuaRCS dataset, for which the mean is 13.9 and the median is 14 (both 56\\% of the maximum score). These are very close together, suggesting a reasonably centrally-concentrated score distrubution, and the low skewness value of 0.1 supports this. The kurtosis of the distribution is negative (platykurtic), which tells us that the distribution of scores is flat rather than peaky.   The most common score (\"mode\") is 10, with 197 (~7%) of participants getting this score, however all score values from 7-21 have counts of greater than 100, supporting the flat nature of the distribution suggested by the negative kurtosis. The interquartile range (25-75 percentiles) is 8 points, and the standard deviation is 5.3. These represent a large fraction (20 and 32\\%) of the entire available score range, respectively, making the distribution quite wide.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add comments\n",
    "data=pd.read_csv('AST200_data_anonymized.csv', encoding=\"ISO-8859-1\")\n",
    "mask = np.where(data == 999)\n",
    "data = data.replace(999,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code computing all descriptive statistics for your categorical variable here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code computing all descriptive statistics for your categorical variable here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your description of categorical distribution here*\n",
    "\n",
    "*Your description of continuous distribution here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Indexing DataFrames\n",
    "To pull up individual rows or entries, the fact that pandas dataframes always print the indices of rows off of their lefthand side helps. You index dataframes with .loc (if using column name) or .iloc (if using column index), as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asteroids.loc[4,\"ra\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asteroids.iloc[4,0] #same because column 0 is \"ra\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can always check that the column you're indexing is the one you want as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asteroids.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and you can index multiple columns/rows in the usual way, which is useful if you want some subset of table rows/columns\n",
    "asteroids.iloc[:10,:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do lots more with this as well, including logical operations to parse the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asteroids.columns\n",
    "ast_new = asteroids[asteroids.dist < 500]\n",
    "ast_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that once again, Python employed the ... syntax to obscure some of the entries in the very large table. If you want to see everything, execute the following commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these set the pandas defaults so that it will print ALL values, even for very long lists and large dataframes\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Making DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to make a data frame from scratch is to just initialize it and then fill it in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.DataFrame()\n",
    "t['name'] = ['Betelgeuse', 'Rigel', 'Sirius', 'Capella']\n",
    "t['flux'] = [1.2, 2.2, 3.1, 4.3]\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then do things like add rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.loc[4] = ['Steve', 10.1]\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And columns too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t['logflux'] = np.log10(t['flux'])  # Compute the log10 of the flux\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Converting Tables to Numpy\n",
    "\n",
    "Sometimes you may not want or be able to use a `Table` object and prefer to work with a plain numpy array (like if you read in data and then want to manipulate it.  This is easily done by passing the table to the `np.array()` constructor.  \n",
    "\n",
    "*This makes a copy of the data*.  If you have a huge table and don't want to waste memory, supply `copy=False` to the constructor, but be warned that changing the output numpy array will change the original table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(t['flux'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=hw>\n",
    "    \n",
    "## Exercise 2 - Intro to the Exoplanet Database\n",
    "--------------\n",
    "\n",
    "Over the next month or so, several of our in-class labs (and your second project) will revolve around a single dataset - the [NASA Exoplanet Archive](https://exoplanetarchive.ipac.caltech.edu/). We will explore this dataset in great detail and apply many of the statistical principles that you have learned and will be learning to it. Today you will begin just by exploring it. At a minimum, you should complete each of the following, but it may behoove you to do a little more exploring as well. For each item in the list below, you should include one or more well-commented code cells and/or a markdown cell with explanations.  \n",
    "    \n",
    "a) Figure out how to read in the data in the file planets_030220.csv. (Hint: you will need to tell Pandas how many rows to skip before the real table begins) and display the table in the notebook.  \n",
    "b) Find out basic information about the table and the types of entries in it, and write a 1 paragraph description of what the exoplanet archive is/contains based on these results.  \n",
    "c) Compute descriptive statistics for at least two columns and describe them in the same way you did in exercise 1d above.   \n",
    "d) Make at least two histograms or boxplots that you think might be informative and describe what they show in words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div.hw {    \n",
       "    background-color: #fcf2f2;\n",
       "    border-color: #dFb5b4;\n",
       "    border-left: 5px solid #dfb5b4;\n",
       "    padding: 0.5em;\n",
       "    }\n",
       " </style>\n",
       "\n",
       "<style>\n",
       "div.sidebar {    \n",
       "    background-color: #d3d3d3;\n",
       "    border-color: #dFb5b4;\n",
       "    border-left: 5px solid #dfb5b4;\n",
       "    padding: 0.5em;\n",
       "    }\n",
       " </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"../../custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
